{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3d83f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reading the file \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(r\"C:\\Users\\kanis\\Major-Project\\wikihowRawArticles\\article01\")\n",
    "f = open(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4139e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to trim all the steps from the clutter\n",
    "def findsteps():\n",
    "    print(\"got steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c8f978",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#taking the only steps \n",
    "Lines = f.readlines()\n",
    "\n",
    "\n",
    "#open the file that will contain the refernce summary \n",
    "file2 = open(r\"C:\\Users\\kanis\\Major-Project\\References\\ref01.txt\",\"w+\")\n",
    "\n",
    "for line in Lines :\n",
    "    if line[0] == '#'and line[1]!='*':\n",
    "        material = \"\"\n",
    "        temp = 1\n",
    "        for char in line :\n",
    "            if temp == 1 :\n",
    "                temp =0  #check to remove hash \n",
    "            else :\n",
    "                material += char\n",
    "            if char == '.':\n",
    "                break;\n",
    "        file2.write(material) #writing the reference summary into the file that was opened\n",
    "file2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb207019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possibly the easiest thing you can do is watch television shows or movies in the language you are trying to learn. Try to avoid subtitles, so you donâ€™t develop a reliance on them. To make things easier, try to watch shows or movies whose plots you are already familiar withâ€”like kids' cartoons or dubbed versions of English movieâ€”knowing the context will help you to decipher the meanings of words and phrases.\n",
      "\n",
      "As your language level progresses, you can move on to more advanced reading material like newspapers and magazines. When you read out loud, rather than silently, you can work on both your overall reading comprehension and pronunciation skills. Rather than trying to translate each phrase, force yourself to think in the language you're reading.\n",
      "\n",
      "Mastering everyday conversation will let you hit the ground running. Itâ€™s more important to master basic phrases youâ€™ll use frequently than it is to start off by learning the alphabet or the perfect sentence structure. \n",
      "\n",
      "Mastering basic vocabulary is probably one of the most important things you can do when learning a new language. Even if you can't understand whole sentences, the ability to pick out keywords can help you to understand the general meaning of a speech or text.\n",
      "\n",
      "There's no point in memorizing hundreds of words and phrases if you pronounce them so oddly that they can't be understood. Therefore, it's important that when you learn a word, you learn the pronunciation simultaneously.\n",
      "\n",
      "The reason why most people can't remember most of the language they spent years learning in school is that school curricula tend to focus a huge amount of time on learning grammar and very little time on speech (or \"comprehensible output\"). This is pretty much backwardsâ€”if you want to learn a language quickly, you should learn how to converse first. The specifics of grammar will come later.\n",
      "\n",
      "Start off with clear goals. Try learning to count to ten since 1-10 is usually the easiest thing to memorize at first. Each day learn a new set of ten numbers, keep going each day until you are satisfied with how high you can count. If you are up for a challenge, memorize all the numbers up to one hundred in one day.\n",
      "\n",
      "In turn, better reading and pronunciation can help you memorize words with greater ease. Plus, it is better for you to be sounding the words out rather than looking at the romanization for the words.\n",
      "\n",
      "Too often, people spend all of their time studying grammar and memorizing lists of words instead of actually going out there and putting what they've learned into practice. Speaking with a real, live person will help you to feel much more motivated about learning the language than staring at a book or computer screen.\n",
      "\n",
      "Carrying a dictionary will allow you to find the necessary word at a moment's notice. This is especially important when you are having a conversation with a native speaker and don't wish to disrupt the flow of conversation by not being able to remember a word. In addition, looking up the word and using it immediately in a sentence will help you to commit the word to memory.\n",
      "\n",
      "Most language learning apps offer both a free version and a pro/premium version with more access to additional lessons and features. Weâ€™ll breakdown each app below:\n",
      "\n",
      "People often claim to have studied a language \"for five years\" and still not be fluent. But when they say five years, they probably mean that they studied the language for only a couple of hours a week over that entire time period. If you want to learn a new language ''quickly'' (that is, in the space of a few weeks or months), you're going to have to commit to studying the language for a couple of hours ''per day''.\n",
      "\n",
      "When you're learning a new language youâ€™ll get further if youâ€™re okay with making mistakes and learning from them. You might find yourself in situations where you donâ€™t quite know the right word, or you donâ€™t understand 100% of what the other personâ€™s saying. Thatâ€™s all a normal part of the language-learning process.\n",
      "\n",
      "If you can visit and spend some time in a country where your new language is spoken, youâ€™ll get to connect with native speakers. Learning a language within the context of culture and everyday life can boost your motivation and offer hands-on learning experiences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting the raw material for the summary generation from the preprocessed \n",
    "\n",
    "file3 = open(r\"C:\\Users\\kanis\\Major-Project\\Intermediate\\itm01.txt\",\"w+\")\n",
    "\n",
    "\n",
    "intermediatelist = []\n",
    "for line in Lines :\n",
    "    if line[0]=='#'and line[1]!='*':\n",
    "        material = \"\"\n",
    "        temp = 1 \n",
    "        for char in line :\n",
    "            if temp == 1 :\n",
    "                if char != '.' :\n",
    "                    continue;\n",
    "                else :\n",
    "                    temp = 0\n",
    "            else :\n",
    "                if char=='â€™':\n",
    "                    char = \"'\"\n",
    "                material+= char   \n",
    "        \n",
    "        intermediatelist.append(material.lstrip())\n",
    "        #file3.write(material.lstrip())\n",
    "        \n",
    "####now remove garbage from the intermediary file####\n",
    "\n",
    "secondlist =[]\n",
    "#removing the hyperlinks\n",
    "for point in intermediatelist :\n",
    "    material = \"\"\n",
    "    i = 0\n",
    "    j = 1\n",
    "    while i<len(point):\n",
    "        if point[i]=='<' and point[j]=='r':\n",
    "            i=i+4\n",
    "            j=j+4\n",
    "            while point[i]!=f and point[j]!='>':\n",
    "                i=i+1\n",
    "                j=j+1\n",
    "            i=i+2 \n",
    "            j=j+2\n",
    "        if i<len(point):\n",
    "            material += point[i]\n",
    "        i=i+1\n",
    "        j=j+1\n",
    "    secondlist.append(material)\n",
    "\n",
    "thirdlist  = []\n",
    "#for removal of image alts \n",
    "for point in secondlist :\n",
    "    material = \"\"\n",
    "    i=0\n",
    "    j=1\n",
    "    while i<len(point) :\n",
    "        if point[i]=='[' and point[j]=='[':\n",
    "            while point[i]!=']' and point[j]!=']':\n",
    "                i = i+1\n",
    "                j = j+1\n",
    "            i=i+2\n",
    "            j=j+2\n",
    "        if i<=len(point)-1 and point[i]!=']':\n",
    "            material+=point[i]\n",
    "        i=i+1\n",
    "        j=j+1\n",
    "    thirdlist.append(material)\n",
    "\n",
    "for point in thirdlist :\n",
    "    print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17236e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now writing the completely preprocessed text into itm file:for example\n",
    "\n",
    "#a new repo is to be made for all the final files though \n",
    "for item in thirdlist :\n",
    "    file3.write(item)\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a89bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Possibly', 'easiest', 'thing', 'watch', 'television', 'show', 'movie', 'language', 'trying', 'learn', 'Try', 'avoid', 'subtitle', 'donâ€™t', 'develop', 'reliance', 'make', 'thing', 'easier', 'try', 'watch', 'show', 'movie', 'whose', 'plot', 'already', 'familiar', 'withâ€', 'like', 'kid', 'cartoon', 'dubbed', 'version', 'English', 'movieâ€', 'knowing', 'context', 'help', 'decipher', 'meaning', 'word', 'phrase'], ['language', 'level', 'progress', 'move', 'advanced', 'reading', 'material', 'like', 'newspaper', 'magazine', 'read', 'loud', 'rather', 'silently', 'work', 'overall', 'reading', 'comprehension', 'pronunciation', 'skill', 'Rather', 'trying', 'translate', 'phrase', 'force', 'think', 'language', 'reading'], ['Mastering', 'everyday', 'conversation', 'let', 'hit', 'ground', 'running', 'Itâ€™s', 'important', 'master', 'basic', 'phrase', 'youâ€™ll', 'use', 'frequently', 'start', 'learning', 'alphabet', 'perfect', 'sentence', 'structure'], ['Mastering', 'basic', 'vocabulary', 'probably', 'one', 'important', 'thing', 'learning', 'new', 'language', 'Even', 'understand', 'whole', 'sentence', 'ability', 'pick', 'keywords', 'help', 'understand', 'general', 'meaning', 'speech', 'text'], ['point', 'memorizing', 'hundred', 'word', 'phrase', 'pronounce', 'oddly', 'understood', 'Therefore', 'important', 'learn', 'word', 'learn', 'pronunciation', 'simultaneously'], ['reason', 'people', 'remember', 'language', 'spent', 'year', 'learning', 'school', 'school', 'curriculum', 'tend', 'focus', 'huge', 'amount', 'time', 'learning', 'grammar', 'little', 'time', 'speech', 'comprehensible', 'output', 'pretty', 'much', 'backwardsâ€', 'want', 'learn', 'language', 'quickly', 'learn', 'converse', 'first', 'specific', 'grammar', 'come', 'later'], ['Start', 'clear', 'goal', 'Try', 'learning', 'count', 'ten', 'since', '1-10', 'usually', 'easiest', 'thing', 'memorize', 'first', 'day', 'learn', 'new', 'set', 'ten', 'number', 'keep', 'going', 'day', 'satisfied', 'high', 'count', 'challenge', 'memorize', 'number', 'one', 'hundred', 'one', 'day'], ['turn', 'better', 'reading', 'pronunciation', 'help', 'memorize', 'word', 'greater', 'ease', 'Plus', 'better', 'sounding', 'word', 'rather', 'looking', 'romanization', 'word'], ['often', 'people', 'spend', 'time', 'studying', 'grammar', 'memorizing', 'list', 'word', 'instead', 'actually', 'going', 'putting', \"'ve\", 'learned', 'practice', 'Speaking', 'real', 'live', 'person', 'help', 'feel', 'much', 'motivated', 'learning', 'language', 'staring', 'book', 'computer', 'screen'], ['Carrying', 'dictionary', 'allow', 'find', 'necessary', 'word', 'moment', 'notice', 'especially', 'important', 'conversation', 'native', 'speaker', 'wish', 'disrupt', 'flow', 'conversation', 'able', 'remember', 'word', 'addition', 'looking', 'word', 'using', 'immediately', 'sentence', 'help', 'commit', 'word', 'memory'], ['language', 'learning', 'apps', 'offer', 'free', 'version', 'pro/premium', 'version', 'access', 'additional', 'lesson', 'feature', 'Weâ€™ll', 'breakdown', 'app'], ['People', 'often', 'claim', 'studied', 'language', 'five', 'year', 'still', 'fluent', 'say', 'five', 'year', 'probably', 'mean', 'studied', 'language', 'couple', 'hour', 'week', 'entire', 'time', 'period', 'want', 'learn', 'new', 'language', 'quickly', 'space', 'week', 'month', 'going', 'commit', 'studying', 'language', 'couple', 'hour', 'per', 'day'], ['learning', 'new', 'language', 'youâ€™ll', 'get', 'youâ€™re', 'okay', 'making', 'mistake', 'learning', 'might', 'find', 'situation', 'donâ€™t', 'quite', 'know', 'right', 'word', 'donâ€™t', 'understand', '100', '%', 'personâ€™s', 'saying', 'Thatâ€™s', 'normal', 'part', 'language-learning', 'process'], ['visit', 'spend', 'time', 'country', 'new', 'language', 'spoken', 'youâ€™ll', 'get', 'connect', 'native', 'speaker', 'Learning', 'language', 'within', 'context', 'culture', 'everyday', 'life', 'boost', 'motivation', 'offer', 'hands-on', 'learning', 'experience']]\n"
     ]
    }
   ],
   "source": [
    "#nltk working \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#print(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize #for tokenization \n",
    "\n",
    "\n",
    "#open the file and read\n",
    "file4 = open(r\"C:\\Users\\kanis\\Major-Project\\Intermediate\\itm01.txt\",\"r+\")\n",
    "Lines = file4.readlines()\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#additional stopwords \n",
    "stop_words.add(',')\n",
    "stop_words.add(\"'\")\n",
    "stop_words.add('.')\n",
    "stop_words.add('(')\n",
    "stop_words.add(')')\n",
    "stop_words.add('\"\"')\n",
    "stop_words.add(\"''\")\n",
    "stop_words.add('`')\n",
    "stop_words.add('~')\n",
    "stop_words.add(':')\n",
    "stop_words.add(';')\n",
    "stop_words.add('!')\n",
    "stop_words.add('”')\n",
    "stop_words.add(\"'re\")\n",
    "stop_words.add(\"'s\")\n",
    "stop_words.add(\"ca\")\n",
    "stop_words.add(\"n't\")\n",
    "stop_words.add(\"``\")\n",
    "stop_words.add(\"'ll\")\n",
    "stop_words.add(\"'ld\")\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.util import ngrams #for generating any n grams\n",
    "\n",
    "check = []\n",
    "\n",
    "finallemma = []\n",
    "\n",
    "for line in Lines :\n",
    "    \n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        \n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_tokens.append(w)\n",
    "    #print(filtered_tokens)\n",
    "    \n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w) for w in filtered_tokens]  #lemmatization \n",
    "    finallemma.append(lemmed)\n",
    "    \n",
    "    #print(lemmed)\n",
    "    \n",
    "    bigrm = list(nltk.bigrams(filtered_tokens))\n",
    "    trigrams = list(ngrams(filtered_tokens,3))\n",
    "print(finallemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4dda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "data_words = []\n",
    "for lis in finallemma :\n",
    "    for w in lis :\n",
    "        data_words.append(w)\n",
    "        \n",
    "#print(data_words)\n",
    "\n",
    "#creating dictionary\n",
    "#id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "#create corpus \n",
    "#texts = data_words\n",
    "\n",
    "#term document frequency\n",
    "#corpus = [id2word.doc2bow(text.split()) for text in texts]\n",
    "\n",
    "#print(corpus)\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378df620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "def my_data():\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    processed_txt = \"\"\n",
    "    for r in data_words:\n",
    "            processed_txt+=str(str(r + \" \"))\n",
    "            yield tokenizer.tokenize(processed_txt)\n",
    "\n",
    "            \n",
    "#creating the dictionary \n",
    "dictionary = corpora.Dictionary(my_data())\n",
    "#print(dictionary)\n",
    "\n",
    "\n",
    "#creating the corpus\n",
    "\n",
    "#creating the term document frequency\n",
    "termdocfreq = [dictionary.doc2bow(text) for text in my_data()]\n",
    "#print(termdocfreq)\n",
    "\n",
    "\n",
    "listsave = []\n",
    "listsave.append(dictionary)\n",
    "listsave.append(termdocfreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd69476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"wb\") as fp:\n",
    "    pickle.dump(listsave,fp)\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5ce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
