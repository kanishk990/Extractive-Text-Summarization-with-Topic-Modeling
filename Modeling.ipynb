{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the variables from file : dictionary and tdf/corpus\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "dictionary = data[0]\n",
    "termdocfreq = data[1]\n",
    "finallemma = data[2]\n",
    "feedtodict = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6384808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.036*\"word\" + 0.032*\"language\" + 0.024*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.015*\"thing\" + 0.014*\"help\" + 0.013*\"one\" + 0.012*\"reading\" + 0.011*\"day\" '\n",
      "  '+ 0.011*\"time\"'),\n",
      " (1,\n",
      "  '0.035*\"language\" + 0.034*\"thing\" + 0.030*\"watch\" + 0.030*\"show\" + '\n",
      "  '0.029*\"movie\" + 0.026*\"reading\" + 0.024*\"phrase\" + 0.024*\"trying\" + '\n",
      "  '0.023*\"like\" + 0.016*\"Possibly\"'),\n",
      " (2,\n",
      "  '0.039*\"word\" + 0.026*\"language\" + 0.023*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.017*\"help\" + 0.014*\"important\" + 0.012*\"thing\" + 0.012*\"phrase\" + '\n",
      "  '0.011*\"reading\" + 0.011*\"conversation\"'),\n",
      " (3,\n",
      "  '0.033*\"language\" + 0.027*\"learning\" + 0.025*\"learn\" + 0.024*\"phrase\" + '\n",
      "  '0.020*\"important\" + 0.019*\"word\" + 0.018*\"thing\" + 0.018*\"reading\" + '\n",
      "  '0.016*\"understand\" + 0.015*\"sentence\"'),\n",
      " (4,\n",
      "  '0.018*\"word\" + 0.017*\"learning\" + 0.016*\"language\" + 0.013*\"learn\" + '\n",
      "  '0.010*\"help\" + 0.009*\"reading\" + 0.008*\"new\" + 0.008*\"phrase\" + '\n",
      "  '0.008*\"grammar\" + 0.008*\"time\"'),\n",
      " (5,\n",
      "  '0.040*\"language\" + 0.031*\"word\" + 0.025*\"learning\" + 0.019*\"learn\" + '\n",
      "  '0.013*\"help\" + 0.012*\"time\" + 0.012*\"new\" + 0.011*\"reading\" + '\n",
      "  '0.011*\"phrase\" + 0.011*\"day\"'),\n",
      " (6,\n",
      "  '0.029*\"learn\" + 0.028*\"language\" + 0.023*\"learning\" + 0.021*\"word\" + '\n",
      "  '0.019*\"thing\" + 0.018*\"phrase\" + 0.017*\"reading\" + 0.014*\"day\" + '\n",
      "  '0.014*\"important\" + 0.013*\"memorize\"'),\n",
      " (7,\n",
      "  '0.031*\"word\" + 0.031*\"language\" + 0.020*\"thing\" + 0.017*\"learn\" + '\n",
      "  '0.016*\"learning\" + 0.015*\"phrase\" + 0.014*\"help\" + 0.013*\"watch\" + '\n",
      "  '0.012*\"reading\" + 0.012*\"trying\"'),\n",
      " (8,\n",
      "  '0.032*\"language\" + 0.032*\"word\" + 0.023*\"learning\" + 0.018*\"phrase\" + '\n",
      "  '0.018*\"learn\" + 0.013*\"reading\" + 0.013*\"help\" + 0.012*\"time\" + '\n",
      "  '0.011*\"sentence\" + 0.010*\"important\"'),\n",
      " (9,\n",
      "  '0.035*\"word\" + 0.025*\"language\" + 0.022*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.018*\"help\" + 0.016*\"reading\" + 0.016*\"phrase\" + 0.015*\"thing\" + '\n",
      "  '0.014*\"important\" + 0.012*\"pronunciation\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=termdocfreq,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=num_topics,random_state=100, chunksize=100, passes=10, per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[termdocfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08924e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.42470777805264603\n",
      "\n",
      "Perplexity:  -5.127869182828577\n"
     ]
    }
   ],
   "source": [
    "#coherence and score \n",
    "from gensim.models import CoherenceModel\n",
    "# instantiate topic coherence model\n",
    "import numpy as np\n",
    "newcorpus = []\n",
    "for lis in finallemma :\n",
    "    for w in lis :\n",
    "        if len(w)>2:\n",
    "            newcorpus.append(w)\n",
    "\n",
    "cm = CoherenceModel(model=lda_model, texts=feedtodict, dictionary=dictionary, coherence='c_v')\n",
    "with np.errstate(invalid='ignore'):\n",
    "    coherence_lda = cm.get_coherence()\n",
    "    print('Coherence: ', coherence_lda)                \n",
    "# getting topic coherence score \n",
    "\n",
    "\n",
    "#getting the perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(termdocfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896b576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#import pyLDAvis\n",
    "#import os \n",
    "#import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "#num_topics = 10\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary,sort_topics = 'false')\n",
    "#vis\n",
    "#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "#LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c2449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "file10 = open(r\"C:\\Users\\kanis\\Major-Project\\Intermediate\\itm01.txt\",\"r+\")\n",
    "\n",
    "Lines = file10.readlines()\n",
    "#print(Lines)\n",
    "x = \"\"\n",
    "for line in Lines:\n",
    "    x = x + line\n",
    "#print(x)\n",
    "tksen = tokenize.sent_tokenize(x)\n",
    "print(len(tksen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2342ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6b7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>Possibly the easiest thing you can do is watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>Try to avoid subtitles, so you donâ€™t develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.774973</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>To make things easier, try to watch shows or m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>As your language level progresses, you can mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>When you read out loud, rather than silently, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.871416</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>Rather than trying to translate each phrase, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887489</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>Mastering everyday conversation will let you h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Itâ€™s more important to master basic phrases ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.909990</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>Mastering basic vocabulary is probably one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.918170</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Even if you can't understand whole sentences, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>There's no point in memorizing hundreds of wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.930760</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>Therefore, it's important that when you learn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.935706</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>The reason why most people can't remember most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943743</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>This is pretty much backwardsâ€”if you want to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947052</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>The specifics of grammar will come later.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.949994</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Start off with clear goals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952626</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>Try learning to count to ten since 1-10 is usu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.954995</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>Each day learn a new set of ten numbers, keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>If you are up for a challenge, memorize all th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959086</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>In turn, better reading and pronunciation can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.960865</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>Plus, it is better for you to be sounding the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Too often, people spend all of their time stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.963996</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Speaking with a real, live person will help yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965381</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Carrying a dictionary will allow you to find t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966663</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>This is especially important when you are havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967854</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>In addition, looking up the word and using it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968962</td>\n",
       "      <td>word, language, learning, learn, thing, help, ...</td>\n",
       "      <td>Most language learning apps offer both a free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.969997</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>Weâ€™ll breakdown each app below:\\nPeople ofte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.970965</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>But when they say five years, they probably me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>word, language, learning, learn, thing, help, ...</td>\n",
       "      <td>If you want to learn a new language ''quickly'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.972724</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>When you're learning a new language youâ€™ll g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.973527</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>You might find yourself in situations where yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Thatâ€™s all a normal part of the language-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>If you can visit and spend some time in a coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.975673</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>Learning a language within the context of cult...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib   \n",
       "0             0               8            0.549954  \\\n",
       "1             1               5            0.699966   \n",
       "2             2               2            0.774973   \n",
       "3             3               3            0.819981   \n",
       "4             4               9            0.849985   \n",
       "5             5               6            0.871416   \n",
       "6             6               2            0.887489   \n",
       "7             7               3            0.899989   \n",
       "8             8               9            0.909990   \n",
       "9             9               1            0.918170   \n",
       "10           10               5            0.924990   \n",
       "11           11               9            0.930760   \n",
       "12           12               8            0.935706   \n",
       "13           13               5            0.943743   \n",
       "14           14               1            0.947052   \n",
       "15           15               7            0.949994   \n",
       "16           16               5            0.952626   \n",
       "17           17               2            0.954995   \n",
       "18           18               3            0.957138   \n",
       "19           19               1            0.959086   \n",
       "20           20               6            0.960865   \n",
       "21           21               1            0.962496   \n",
       "22           22               7            0.963996   \n",
       "23           23               3            0.965381   \n",
       "24           24               2            0.966663   \n",
       "25           25               2            0.967854   \n",
       "26           26               0            0.968962   \n",
       "27           27               5            0.969997   \n",
       "28           28               9            0.970965   \n",
       "29           29               0            0.971872   \n",
       "30           30               8            0.972724   \n",
       "31           31               4            0.973527   \n",
       "32           32               7            0.974283   \n",
       "33           33               5            0.974997   \n",
       "34           34               6            0.975673   \n",
       "\n",
       "                                             Keywords   \n",
       "0   language, word, learning, phrase, learn, readi...  \\\n",
       "1   language, word, learning, learn, help, time, n...   \n",
       "2   word, language, learning, learn, help, importa...   \n",
       "3   language, learning, learn, phrase, important, ...   \n",
       "4   word, language, learning, learn, help, reading...   \n",
       "5   learn, language, learning, word, thing, phrase...   \n",
       "6   word, language, learning, learn, help, importa...   \n",
       "7   language, learning, learn, phrase, important, ...   \n",
       "8   word, language, learning, learn, help, reading...   \n",
       "9   language, thing, watch, show, movie, reading, ...   \n",
       "10  language, word, learning, learn, help, time, n...   \n",
       "11  word, language, learning, learn, help, reading...   \n",
       "12  language, word, learning, phrase, learn, readi...   \n",
       "13  language, word, learning, learn, help, time, n...   \n",
       "14  language, thing, watch, show, movie, reading, ...   \n",
       "15  word, language, thing, learn, learning, phrase...   \n",
       "16  language, word, learning, learn, help, time, n...   \n",
       "17  word, language, learning, learn, help, importa...   \n",
       "18  language, learning, learn, phrase, important, ...   \n",
       "19  language, thing, watch, show, movie, reading, ...   \n",
       "20  learn, language, learning, word, thing, phrase...   \n",
       "21  language, thing, watch, show, movie, reading, ...   \n",
       "22  word, language, thing, learn, learning, phrase...   \n",
       "23  language, learning, learn, phrase, important, ...   \n",
       "24  word, language, learning, learn, help, importa...   \n",
       "25  word, language, learning, learn, help, importa...   \n",
       "26  word, language, learning, learn, thing, help, ...   \n",
       "27  language, word, learning, learn, help, time, n...   \n",
       "28  word, language, learning, learn, help, reading...   \n",
       "29  word, language, learning, learn, thing, help, ...   \n",
       "30  language, word, learning, phrase, learn, readi...   \n",
       "31  word, learning, language, learn, help, reading...   \n",
       "32  word, language, thing, learn, learning, phrase...   \n",
       "33  language, word, learning, learn, help, time, n...   \n",
       "34  learn, language, learning, word, thing, phrase...   \n",
       "\n",
       "                                                 Text  \n",
       "0   Possibly the easiest thing you can do is watch...  \n",
       "1   Try to avoid subtitles, so you donâ€™t develop...  \n",
       "2   To make things easier, try to watch shows or m...  \n",
       "3   As your language level progresses, you can mov...  \n",
       "4   When you read out loud, rather than silently, ...  \n",
       "5   Rather than trying to translate each phrase, f...  \n",
       "6   Mastering everyday conversation will let you h...  \n",
       "7   Itâ€™s more important to master basic phrases ...  \n",
       "8   Mastering basic vocabulary is probably one of ...  \n",
       "9   Even if you can't understand whole sentences, ...  \n",
       "10  There's no point in memorizing hundreds of wor...  \n",
       "11  Therefore, it's important that when you learn ...  \n",
       "12  The reason why most people can't remember most...  \n",
       "13  This is pretty much backwardsâ€”if you want to...  \n",
       "14          The specifics of grammar will come later.  \n",
       "15                        Start off with clear goals.  \n",
       "16  Try learning to count to ten since 1-10 is usu...  \n",
       "17  Each day learn a new set of ten numbers, keep ...  \n",
       "18  If you are up for a challenge, memorize all th...  \n",
       "19  In turn, better reading and pronunciation can ...  \n",
       "20  Plus, it is better for you to be sounding the ...  \n",
       "21  Too often, people spend all of their time stud...  \n",
       "22  Speaking with a real, live person will help yo...  \n",
       "23  Carrying a dictionary will allow you to find t...  \n",
       "24  This is especially important when you are havi...  \n",
       "25  In addition, looking up the word and using it ...  \n",
       "26  Most language learning apps offer both a free ...  \n",
       "27  Weâ€™ll breakdown each app below:\\nPeople ofte...  \n",
       "28  But when they say five years, they probably me...  \n",
       "29  If you want to learn a new language ''quickly'...  \n",
       "30  When you're learning a new language youâ€™ll g...  \n",
       "31  You might find yourself in situations where yo...  \n",
       "32  Thatâ€™s all a normal part of the language-lea...  \n",
       "33  If you can visit and spend some time in a coun...  \n",
       "34  Learning a language within the context of cult...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the dominant topics \n",
    "import random\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts=tksen):\n",
    "    # Init output\n",
    "    \n",
    "    dp = []\n",
    "    pc = []\n",
    "    tk = []\n",
    "    \n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        #print(row_list)\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                x = random.randint(0, 9)\n",
    "                topic_num=(topic_num+x)%10\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                #print(topic_keywords + \" \"+str(topic_num)+\" \"+str(prop_topic))\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, pd.Series([int(topic_num), round(prop_topic,4), topic_keywords])], ignore_index=True)\n",
    "                #df = pd.DataFrame({'Dominant_Topic': topic_num,'Perc_Contribution':prop_topic,'Topic_Keywords':topic_keywords})\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, df], ignore_index=True)\n",
    "                dp.append(topic_num)\n",
    "                pc.append(prop_topic)\n",
    "                tk.append(topic_keywords)\n",
    "            else:\n",
    "                break\n",
    "   \n",
    "    sent_topics_df = pd.DataFrame({'Dominant_Topic' : dp, 'Perc_contribution':pc, 'topic_keywords':tk })\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "    \n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts = tksen)\n",
    "df_len=len(df_topic_sents_keywords.index)\n",
    "df_topic_sents_keywords=df_topic_sents_keywords.drop(df_topic_sents_keywords.index[len(tksen):])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_len=len(df_topic_sents_keywords.index)\n",
    "print(df_len)\n",
    "df_dominant_topic.head(df_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a63fb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>word, language, learning, learn, thing, help, ...</td>\n",
       "      <td>If you want to learn a new language ''quickly'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Too often, people spend all of their time stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.967854</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>In addition, looking up the word and using it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965381</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Carrying a dictionary will allow you to find t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.973527</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>You might find yourself in situations where yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>If you can visit and spend some time in a coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.975673</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>Learning a language within the context of cult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Thatâ€™s all a normal part of the language-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.972724</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>When you're learning a new language youâ€™ll g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.970965</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>But when they say five years, they probably me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib   \n",
       "0          0            0.971872  \\\n",
       "1          1            0.962496   \n",
       "2          2            0.967854   \n",
       "3          3            0.965381   \n",
       "4          4            0.973527   \n",
       "5          5            0.974997   \n",
       "6          6            0.975673   \n",
       "7          7            0.974283   \n",
       "8          8            0.972724   \n",
       "9          9            0.970965   \n",
       "\n",
       "                                            Keywords   \n",
       "0  word, language, learning, learn, thing, help, ...  \\\n",
       "1  language, thing, watch, show, movie, reading, ...   \n",
       "2  word, language, learning, learn, help, importa...   \n",
       "3  language, learning, learn, phrase, important, ...   \n",
       "4  word, learning, language, learn, help, reading...   \n",
       "5  language, word, learning, learn, help, time, n...   \n",
       "6  learn, language, learning, word, thing, phrase...   \n",
       "7  word, language, thing, learn, learning, phrase...   \n",
       "8  language, word, learning, phrase, learn, readi...   \n",
       "9  word, language, learning, learn, help, reading...   \n",
       "\n",
       "                                                Text  \n",
       "0  If you want to learn a new language ''quickly'...  \n",
       "1  Too often, people spend all of their time stud...  \n",
       "2  In addition, looking up the word and using it ...  \n",
       "3  Carrying a dictionary will allow you to find t...  \n",
       "4  You might find yourself in situations where yo...  \n",
       "5  If you can visit and spend some time in a coun...  \n",
       "6  Learning a language within the context of cult...  \n",
       "7  Thatâ€™s all a normal part of the language-lea...  \n",
       "8  When you're learning a new language youâ€™ll g...  \n",
       "9  But when they say five years, they probably me...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(len(tksen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fd90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet.to_csv(r\"C:\\Users\\kanis\\Major-Project\\PreClusteringData\\mrdfet.csv\")\n",
    "#saving the most representative document for each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c2b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv(r\"C:\\Users\\kanis\\Major-Project\\PreClusteringData\\dt.csv\")\n",
    "#saving the topic wise information for each sentence or document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e32411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Even if you can't understand whole sentences, the ability to pick out keywords can help you to understand the general meaning of a speech or text.\", 'The specifics of grammar will come later.', 'In turn, better reading and pronunciation can help you memorize words with greater ease.', \"Too often, people spend all of their time studying grammar and memorizing lists of words instead of actually going out there and putting what they've learned into practice.\"]\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "\n",
    "#making the list of clusters with their sentences classfied accordingly \n",
    "listofclusters = [None] * num_topics\n",
    "for i in range(num_topics):\n",
    "    listofclusters[i] = []\n",
    "\n",
    "with open(r'C:\\Users\\kanis\\Major-Project\\PreClusteringData\\dt.csv', 'r',encoding=\"utf8\") as csvfile :\n",
    "    datareader = csv.reader(csvfile)\n",
    "    for row in datareader:\n",
    "        if row[0] == '':\n",
    "            continue\n",
    "        listofclusters[int(row[2])].append(row[5])\n",
    "     \n",
    "    \n",
    "#loop for reprsentation\n",
    "i = 0\n",
    "for item in listofclusters :\n",
    "    #print(\"topic cluster no. \"+str(i))\n",
    "    #for sentence in item:\n",
    "        #print(sentence)\n",
    "    #print()\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8b2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d78b43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db4775f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofsentence_vectors = []\n",
    "sentence_vectors = []\n",
    "for sentences in listofclusters:\n",
    "    for i in sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vectors.append(v)\n",
    "    listofsentence_vectors.append(sentence_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da61628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c385e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "k = 0\n",
    "\n",
    "listofsimmatrix = []\n",
    "for sentences in listofclusters:\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    #We will use Cosine Similarity to compute the similarity between a pair of sentences.\n",
    "\n",
    "\n",
    "#And initialize the matrix with cosine similarity scores.\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(listofsentence_vectors[k][i].reshape(1,100), listofsentence_vectors[k][j].reshape(1,100))[0,0]\n",
    "    k=k+1\n",
    "    listofsimmatrix.append(sim_mat)\n",
    "#print(len(listofsimmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a610e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofsubsum = [None] * num_topics\n",
    "for i in range(num_topics):\n",
    "    listofsubsum[i] = []\n",
    "\n",
    "k = 0\n",
    "for sim_mat in listofsimmatrix:\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(listofclusters[k])), reverse=True)\n",
    "    for i in range(int(len(ranked_sentences)/3)):\n",
    "        listofsubsum[k].append(ranked_sentences[i][1])\n",
    "    k=k+1\n",
    "#print(listofsubsum)\n",
    "#print()\n",
    "#print(listofclusters)\n",
    "\n",
    "\n",
    "#generating the final list\n",
    "finallist = []\n",
    "for lis in listofsubsum :\n",
    "    for sent in lis :\n",
    "        if len(sent)>0:\n",
    "            finallist.append(sent)\n",
    "#print(finallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "be34f493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mastering everyday conversation will let you hit the ground running. Itâ€™s more important to master basic phrases youâ€™ll use frequently than it is to start off by learning the alphabet or the perfect sentence structure. Mastering basic vocabulary is probably one of the most important things you can do when learning a new language. There's no point in memorizing hundreds of words and phrases if you pronounce them so oddly that they can't be understood. The reason why most people can't remember most of the language they spent years learning in school is that school curricula tend to focus a huge amount of time on learning grammar and very little time on speech (or \"comprehensible output\"). This is pretty much backwardsâ€”if you want to learn a language quickly, you should learn how to converse first. The specifics of grammar will come later. Plus, it is better for you to be sounding the words out rather than looking at the romanization for the words. Speaking with a real, live person will help you to feel much more motivated about learning the language than staring at a book or computer screen. \n"
     ]
    }
   ],
   "source": [
    "#creating dictionary to arrange summaryin chronological order\n",
    "dictofsent = {}\n",
    "k = 0\n",
    "for sent in tksen :\n",
    "    dictofsent[sent] = k\n",
    "    k=k+1\n",
    "summarytosave=sorted(finallist, key=dictofsent.get)\n",
    "#print(summarytosave)\n",
    "\n",
    "sample = \"\"\n",
    "for sent in summarytosave:\n",
    "    sample += sent \n",
    "    sample += ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab80c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
