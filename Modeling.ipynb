{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df4215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the variables from file : dictionary and tdf/corpus\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "dictionary = data[0]\n",
    "termdocfreq = data[1]\n",
    "finallemma = data[2]\n",
    "feedtodict = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6384808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.037*\"word\" + 0.031*\"language\" + 0.023*\"learning\" + 0.021*\"learn\" + '\n",
      "  '0.015*\"help\" + 0.014*\"thing\" + 0.013*\"one\" + 0.012*\"reading\" + '\n",
      "  '0.011*\"important\" + 0.011*\"day\"'),\n",
      " (1,\n",
      "  '0.035*\"language\" + 0.034*\"thing\" + 0.030*\"watch\" + 0.030*\"show\" + '\n",
      "  '0.029*\"movie\" + 0.026*\"reading\" + 0.024*\"phrase\" + 0.024*\"trying\" + '\n",
      "  '0.023*\"like\" + 0.017*\"Possibly\"'),\n",
      " (2,\n",
      "  '0.038*\"word\" + 0.027*\"language\" + 0.023*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.017*\"help\" + 0.013*\"important\" + 0.012*\"thing\" + 0.012*\"phrase\" + '\n",
      "  '0.011*\"reading\" + 0.011*\"time\"'),\n",
      " (3,\n",
      "  '0.033*\"language\" + 0.027*\"learning\" + 0.025*\"learn\" + 0.024*\"phrase\" + '\n",
      "  '0.020*\"important\" + 0.019*\"word\" + 0.018*\"thing\" + 0.018*\"reading\" + '\n",
      "  '0.015*\"understand\" + 0.014*\"sentence\"'),\n",
      " (4,\n",
      "  '0.018*\"word\" + 0.017*\"learning\" + 0.016*\"language\" + 0.013*\"learn\" + '\n",
      "  '0.010*\"help\" + 0.009*\"reading\" + 0.008*\"new\" + 0.008*\"phrase\" + '\n",
      "  '0.008*\"grammar\" + 0.008*\"time\"'),\n",
      " (5,\n",
      "  '0.041*\"language\" + 0.031*\"word\" + 0.025*\"learning\" + 0.019*\"learn\" + '\n",
      "  '0.013*\"help\" + 0.012*\"time\" + 0.012*\"new\" + 0.011*\"reading\" + 0.011*\"day\" + '\n",
      "  '0.011*\"phrase\"'),\n",
      " (6,\n",
      "  '0.029*\"learn\" + 0.028*\"language\" + 0.023*\"learning\" + 0.022*\"word\" + '\n",
      "  '0.018*\"thing\" + 0.018*\"phrase\" + 0.017*\"reading\" + 0.014*\"day\" + '\n",
      "  '0.014*\"important\" + 0.014*\"memorize\"'),\n",
      " (7,\n",
      "  '0.032*\"word\" + 0.031*\"language\" + 0.020*\"thing\" + 0.017*\"learn\" + '\n",
      "  '0.016*\"learning\" + 0.015*\"phrase\" + 0.014*\"help\" + 0.013*\"watch\" + '\n",
      "  '0.012*\"reading\" + 0.012*\"trying\"'),\n",
      " (8,\n",
      "  '0.032*\"language\" + 0.032*\"word\" + 0.023*\"learning\" + 0.018*\"phrase\" + '\n",
      "  '0.018*\"learn\" + 0.013*\"reading\" + 0.013*\"help\" + 0.012*\"time\" + '\n",
      "  '0.011*\"sentence\" + 0.010*\"important\"'),\n",
      " (9,\n",
      "  '0.035*\"word\" + 0.025*\"language\" + 0.022*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.018*\"help\" + 0.016*\"reading\" + 0.016*\"phrase\" + 0.014*\"thing\" + '\n",
      "  '0.014*\"important\" + 0.012*\"pronunciation\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=termdocfreq,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=num_topics,random_state=100, chunksize=100, passes=10, per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[termdocfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17c2449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "file10 = open(r\"C:\\Users\\kanis\\Major-Project\\Intermediate\\itm01.txt\",\"r+\")\n",
    "\n",
    "Lines = file10.readlines()\n",
    "#print(Lines)\n",
    "x = \"\"\n",
    "for line in Lines:\n",
    "    x = x + line\n",
    "#print(x)\n",
    "tksen = tokenize.sent_tokenize(x)\n",
    "print(len(tksen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a2ddef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0::['word', 'language', 'learning', 'learn', 'help']\n",
      "1::['language', 'thing', 'watch', 'show', 'movie']\n",
      "2::['word', 'language', 'learning', 'learn', 'help']\n",
      "3::['language', 'learning', 'learn', 'phrase', 'important']\n",
      "4::['word', 'learning', 'language', 'learn', 'help']\n",
      "5::['language', 'word', 'learning', 'learn', 'help']\n",
      "6::['learn', 'language', 'learning', 'word', 'thing']\n",
      "7::['word', 'language', 'thing', 'learn', 'learning']\n",
      "8::['language', 'word', 'learning', 'phrase', 'learn']\n",
      "9::['word', 'language', 'learning', 'learn', 'help']\n",
      "\n",
      "{'Possibly the easiest thing you can do is watch television shows or movies in the language you are trying to learn.': 0.02631578947368421, 'Try to avoid subtitles, so you donâ€™t develop a reliance on them.': 0.0, \"To make things easier, try to watch shows or movies whose plots you are already familiar withâ€”like kids' cartoons or dubbed versions of English movieâ€”knowing the context will help you to decipher the meanings of words and phrases.\": 0.008547008547008548, 'As your language level progresses, you can move on to more advanced reading material like newspapers and magazines.': 0.008695652173913044, 'When you read out loud, rather than silently, you can work on both your overall reading comprehension and pronunciation skills.': 0.0, \"Rather than trying to translate each phrase, force yourself to think in the language you're reading.\": 0.01, 'Mastering everyday conversation will let you hit the ground running.': 0.0, 'Itâ€™s more important to master basic phrases youâ€™ll use frequently than it is to start off by learning the alphabet or the perfect sentence structure.': 0.013071895424836602, 'Mastering basic vocabulary is probably one of the most important things you can do when learning a new language.': 0.017857142857142856, \"Even if you can't understand whole sentences, the ability to pick out keywords can help you to understand the general meaning of a speech or text.\": 0.00684931506849315, \"There's no point in memorizing hundreds of words and phrases if you pronounce them so oddly that they can't be understood.\": 0.0, \"Therefore, it's important that when you learn a word, you learn the pronunciation simultaneously.\": 0.030927835051546393, 'The reason why most people can\\'t remember most of the language they spent years learning in school is that school curricula tend to focus a huge amount of time on learning grammar and very little time on speech (or \"comprehensible output\").': 0.0125, 'This is pretty much backwardsâ€”if you want to learn a language quickly, you should learn how to converse first.': 0.026785714285714284, 'The specifics of grammar will come later.': 0.0, 'Start off with clear goals.': 0.0, 'Try learning to count to ten since 1-10 is usually the easiest thing to memorize at first.': 0.022222222222222223, 'Each day learn a new set of ten numbers, keep going each day until you are satisfied with how high you can count.': 0.008849557522123894, 'If you are up for a challenge, memorize all the numbers up to one hundred in one day.': 0.0, 'In turn, better reading and pronunciation can help you memorize words with greater ease.': 0.011363636363636364, 'Plus, it is better for you to be sounding the words out rather than looking at the romanization for the words.': 0.0, \"Too often, people spend all of their time studying grammar and memorizing lists of words instead of actually going out there and putting what they've learned into practice.\": 0.0, 'Speaking with a real, live person will help you to feel much more motivated about learning the language than staring at a book or computer screen.': 0.02054794520547945, \"Carrying a dictionary will allow you to find the necessary word at a moment's notice.\": 0.011764705882352941, \"This is especially important when you are having a conversation with a native speaker and don't wish to disrupt the flow of conversation by not being able to remember a word.\": 0.005747126436781609, 'In addition, looking up the word and using it immediately in a sentence will help you to commit the word to memory.': 0.02608695652173913, 'Most language learning apps offer both a free version and a pro/premium version with more access to additional lessons and features.': 0.015151515151515152, 'Weâ€™ll breakdown each app below:\\nPeople often claim to have studied a language \"for five years\" and still not be fluent.': 0.008264462809917356, 'But when they say five years, they probably mean that they studied the language for only a couple of hours a week over that entire time period.': 0.006993006993006993, \"If you want to learn a new language ''quickly'' (that is, in the space of a few weeks or months), you're going to have to commit to studying the language for a couple of hours ''per day''.\": 0.015957446808510637, \"When you're learning a new language youâ€™ll get further if youâ€™re okay with making mistakes and learning from them.\": 0.025423728813559324, 'You might find yourself in situations where you donâ€™t quite know the right word, or you donâ€™t understand 100% of what the other personâ€™s saying.': 0.0, 'Thatâ€™s all a normal part of the language-learning process.': 0.0, 'If you can visit and spend some time in a country where your new language is spoken, youâ€™ll get to connect with native speakers.': 0.007692307692307693, 'Learning a language within the context of culture and everyday life can boost your motivation and offer hands-on learning experiences.': 0.014925373134328358}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "x=lda_model.show_topics(num_topics=num_topics, num_words=5,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Topics and Words\n",
    "for topic,words in topics_words:\n",
    "    print(str(topic)+ \"::\"+ str(words))\n",
    "print()\n",
    "\n",
    "dict = {}\n",
    "\n",
    "\n",
    "for topic,words in topics_words:\n",
    "    for word in words :\n",
    "        dict[word] = 0\n",
    "#print(dict)\n",
    "\n",
    "s_w = {}\n",
    "for sentence in tksen:\n",
    "    count = 0\n",
    "    for word in sentence.split() :\n",
    "        \n",
    "        if word in dict:\n",
    "            count = count+1\n",
    "    s_w[sentence] = count/len(sentence)\n",
    "keys = list(s_w.keys())\n",
    "values = list(s_w.values())\n",
    "sorted_value_index =np.argsort(values)\n",
    "sorted_dict = {keys[i]: values[i] for i in sorted_value_index}\n",
    "\n",
    "\n",
    "\n",
    "print(s_w)\n",
    "avgvalue = 0\n",
    "for ele in s_w:\n",
    "    avgvalue += s_w[ele]\n",
    "    \n",
    "avgvalue = (avgvalue)/len(s_w)\n",
    "summarylex = []\n",
    "for ele in s_w:\n",
    "    if s_w[ele] > avgvalue :\n",
    "        summarylex.append(ele)\n",
    "print(len(summarylex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d08924e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.4159869142718115\n",
      "\n",
      "Perplexity:  -5.128002204831172\n"
     ]
    }
   ],
   "source": [
    "#coherence and score \n",
    "from gensim.models import CoherenceModel\n",
    "# instantiate topic coherence model\n",
    "import numpy as np\n",
    "newcorpus = []\n",
    "for lis in finallemma :\n",
    "    for w in lis :\n",
    "        if len(w)>2:\n",
    "            newcorpus.append(w)\n",
    "\n",
    "cm = CoherenceModel(model=lda_model, texts=feedtodict, dictionary=dictionary, coherence='c_v')\n",
    "with np.errstate(invalid='ignore'):\n",
    "    coherence_lda = cm.get_coherence()\n",
    "    print('Coherence: ', coherence_lda)                \n",
    "# getting topic coherence score \n",
    "\n",
    "\n",
    "#getting the perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(termdocfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "896b576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#import pyLDAvis\n",
    "#import os \n",
    "#import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "#num_topics = 10\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary,sort_topics = 'false')\n",
    "#vis\n",
    "#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "#LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2342ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a6b7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>Possibly the easiest thing you can do is watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>Try to avoid subtitles, so you donâ€™t develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.774973</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>To make things easier, try to watch shows or m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>As your language level progresses, you can mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>When you read out loud, rather than silently, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871417</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>Rather than trying to translate each phrase, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.887489</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Mastering everyday conversation will let you h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899989</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Itâ€™s more important to master basic phrases ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909990</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Mastering basic vocabulary is probably one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918171</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Even if you can't understand whole sentences, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>There's no point in memorizing hundreds of wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.930760</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>Therefore, it's important that when you learn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.935706</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>The reason why most people can't remember most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943743</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>This is pretty much backwardsâ€”if you want to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947052</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>The specifics of grammar will come later.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949994</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Start off with clear goals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952626</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>Try learning to count to ten since 1-10 is usu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954995</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>Each day learn a new set of ten numbers, keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>If you are up for a challenge, memorize all th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.959086</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>In turn, better reading and pronunciation can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.960865</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>Plus, it is better for you to be sounding the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>Too often, people spend all of their time stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963996</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>Speaking with a real, live person will help yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>0.965381</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>Carrying a dictionary will allow you to find t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966663</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>This is especially important when you are havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967854</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>In addition, looking up the word and using it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.968962</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Most language learning apps offer both a free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>0.969997</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>Weâ€™ll breakdown each app below:\\nPeople ofte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0.970965</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>But when they say five years, they probably me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>If you want to learn a new language ''quickly'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.972724</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>When you're learning a new language youâ€™ll g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>0.973527</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>You might find yourself in situations where yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Thatâ€™s all a normal part of the language-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>If you can visit and spend some time in a coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>0.975673</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Learning a language within the context of cult...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib   \n",
       "0             0               2            0.549954  \\\n",
       "1             1               4            0.699966   \n",
       "2             2               9            0.774973   \n",
       "3             3               0            0.819981   \n",
       "4             4               3            0.849985   \n",
       "5             5               0            0.871417   \n",
       "6             6               3            0.887489   \n",
       "7             7               1            0.899989   \n",
       "8             8               3            0.909990   \n",
       "9             9               3            0.918171   \n",
       "10           10               5            0.924990   \n",
       "11           11               6            0.930760   \n",
       "12           12               4            0.935706   \n",
       "13           13               2            0.943743   \n",
       "14           14               0            0.947052   \n",
       "15           15               1            0.949994   \n",
       "16           16               2            0.952626   \n",
       "17           17               0            0.954995   \n",
       "18           18               7            0.957138   \n",
       "19           19               5            0.959086   \n",
       "20           20               9            0.960865   \n",
       "21           21               1            0.962496   \n",
       "22           22               4            0.963996   \n",
       "23           23               8            0.965381   \n",
       "24           24               1            0.966663   \n",
       "25           25               3            0.967854   \n",
       "26           26               3            0.968962   \n",
       "27           27               9            0.969997   \n",
       "28           28               8            0.970965   \n",
       "29           29               0            0.971872   \n",
       "30           30               4            0.972724   \n",
       "31           31               9            0.973527   \n",
       "32           32               3            0.974283   \n",
       "33           33               6            0.974997   \n",
       "34           34               7            0.975673   \n",
       "\n",
       "                                             Keywords   \n",
       "0   word, language, learning, learn, help, importa...  \\\n",
       "1   word, learning, language, learn, help, reading...   \n",
       "2   word, language, learning, learn, help, reading...   \n",
       "3   word, language, learning, learn, help, thing, ...   \n",
       "4   language, learning, learn, phrase, important, ...   \n",
       "5   word, language, learning, learn, help, thing, ...   \n",
       "6   language, learning, learn, phrase, important, ...   \n",
       "7   language, thing, watch, show, movie, reading, ...   \n",
       "8   language, learning, learn, phrase, important, ...   \n",
       "9   language, learning, learn, phrase, important, ...   \n",
       "10  language, word, learning, learn, help, time, n...   \n",
       "11  learn, language, learning, word, thing, phrase...   \n",
       "12  word, learning, language, learn, help, reading...   \n",
       "13  word, language, learning, learn, help, importa...   \n",
       "14  word, language, learning, learn, help, thing, ...   \n",
       "15  language, thing, watch, show, movie, reading, ...   \n",
       "16  word, language, learning, learn, help, importa...   \n",
       "17  word, language, learning, learn, help, thing, ...   \n",
       "18  word, language, thing, learn, learning, phrase...   \n",
       "19  language, word, learning, learn, help, time, n...   \n",
       "20  word, language, learning, learn, help, reading...   \n",
       "21  language, thing, watch, show, movie, reading, ...   \n",
       "22  word, learning, language, learn, help, reading...   \n",
       "23  language, word, learning, phrase, learn, readi...   \n",
       "24  language, thing, watch, show, movie, reading, ...   \n",
       "25  language, learning, learn, phrase, important, ...   \n",
       "26  language, learning, learn, phrase, important, ...   \n",
       "27  word, language, learning, learn, help, reading...   \n",
       "28  language, word, learning, phrase, learn, readi...   \n",
       "29  word, language, learning, learn, help, thing, ...   \n",
       "30  word, learning, language, learn, help, reading...   \n",
       "31  word, language, learning, learn, help, reading...   \n",
       "32  language, learning, learn, phrase, important, ...   \n",
       "33  learn, language, learning, word, thing, phrase...   \n",
       "34  word, language, thing, learn, learning, phrase...   \n",
       "\n",
       "                                                 Text  \n",
       "0   Possibly the easiest thing you can do is watch...  \n",
       "1   Try to avoid subtitles, so you donâ€™t develop...  \n",
       "2   To make things easier, try to watch shows or m...  \n",
       "3   As your language level progresses, you can mov...  \n",
       "4   When you read out loud, rather than silently, ...  \n",
       "5   Rather than trying to translate each phrase, f...  \n",
       "6   Mastering everyday conversation will let you h...  \n",
       "7   Itâ€™s more important to master basic phrases ...  \n",
       "8   Mastering basic vocabulary is probably one of ...  \n",
       "9   Even if you can't understand whole sentences, ...  \n",
       "10  There's no point in memorizing hundreds of wor...  \n",
       "11  Therefore, it's important that when you learn ...  \n",
       "12  The reason why most people can't remember most...  \n",
       "13  This is pretty much backwardsâ€”if you want to...  \n",
       "14          The specifics of grammar will come later.  \n",
       "15                        Start off with clear goals.  \n",
       "16  Try learning to count to ten since 1-10 is usu...  \n",
       "17  Each day learn a new set of ten numbers, keep ...  \n",
       "18  If you are up for a challenge, memorize all th...  \n",
       "19  In turn, better reading and pronunciation can ...  \n",
       "20  Plus, it is better for you to be sounding the ...  \n",
       "21  Too often, people spend all of their time stud...  \n",
       "22  Speaking with a real, live person will help yo...  \n",
       "23  Carrying a dictionary will allow you to find t...  \n",
       "24  This is especially important when you are havi...  \n",
       "25  In addition, looking up the word and using it ...  \n",
       "26  Most language learning apps offer both a free ...  \n",
       "27  Weâ€™ll breakdown each app below:\\nPeople ofte...  \n",
       "28  But when they say five years, they probably me...  \n",
       "29  If you want to learn a new language ''quickly'...  \n",
       "30  When you're learning a new language youâ€™ll g...  \n",
       "31  You might find yourself in situations where yo...  \n",
       "32  Thatâ€™s all a normal part of the language-lea...  \n",
       "33  If you can visit and spend some time in a coun...  \n",
       "34  Learning a language within the context of cult...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the dominant topics \n",
    "import random\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts=tksen):\n",
    "    # Init output\n",
    "    \n",
    "    dp = []\n",
    "    pc = []\n",
    "    tk = []\n",
    "    \n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        #print(row_list)\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                x = random.randint(0, 9)\n",
    "                topic_num=(topic_num+x)%10\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                #print(topic_keywords + \" \"+str(topic_num)+\" \"+str(prop_topic))\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, pd.Series([int(topic_num), round(prop_topic,4), topic_keywords])], ignore_index=True)\n",
    "                #df = pd.DataFrame({'Dominant_Topic': topic_num,'Perc_Contribution':prop_topic,'Topic_Keywords':topic_keywords})\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, df], ignore_index=True)\n",
    "                dp.append(topic_num)\n",
    "                pc.append(prop_topic)\n",
    "                tk.append(topic_keywords)\n",
    "            else:\n",
    "                break\n",
    "   \n",
    "    sent_topics_df = pd.DataFrame({'Dominant_Topic' : dp, 'Perc_contribution':pc, 'topic_keywords':tk })\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "    \n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts = tksen)\n",
    "df_len=len(df_topic_sents_keywords.index)\n",
    "df_topic_sents_keywords=df_topic_sents_keywords.drop(df_topic_sents_keywords.index[len(tksen):])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_len=len(df_topic_sents_keywords.index)\n",
    "print(df_len)\n",
    "df_dominant_topic.head(df_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a63fb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.971872</td>\n",
       "      <td>word, language, learning, learn, help, thing, ...</td>\n",
       "      <td>If you want to learn a new language ''quickly'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966663</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>This is especially important when you are havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.952626</td>\n",
       "      <td>word, language, learning, learn, help, importa...</td>\n",
       "      <td>Try learning to count to ten since 1-10 is usu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.974283</td>\n",
       "      <td>language, learning, learn, phrase, important, ...</td>\n",
       "      <td>Thatâ€™s all a normal part of the language-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.972724</td>\n",
       "      <td>word, learning, language, learn, help, reading...</td>\n",
       "      <td>When you're learning a new language youâ€™ll g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.959086</td>\n",
       "      <td>language, word, learning, learn, help, time, n...</td>\n",
       "      <td>In turn, better reading and pronunciation can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>learn, language, learning, word, thing, phrase...</td>\n",
       "      <td>If you can visit and spend some time in a coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.975673</td>\n",
       "      <td>word, language, thing, learn, learning, phrase...</td>\n",
       "      <td>Learning a language within the context of cult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.970965</td>\n",
       "      <td>language, word, learning, phrase, learn, readi...</td>\n",
       "      <td>But when they say five years, they probably me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.973527</td>\n",
       "      <td>word, language, learning, learn, help, reading...</td>\n",
       "      <td>You might find yourself in situations where yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib   \n",
       "0          0            0.971872  \\\n",
       "1          1            0.966663   \n",
       "2          2            0.952626   \n",
       "3          3            0.974283   \n",
       "4          4            0.972724   \n",
       "5          5            0.959086   \n",
       "6          6            0.974997   \n",
       "7          7            0.975673   \n",
       "8          8            0.970965   \n",
       "9          9            0.973527   \n",
       "\n",
       "                                            Keywords   \n",
       "0  word, language, learning, learn, help, thing, ...  \\\n",
       "1  language, thing, watch, show, movie, reading, ...   \n",
       "2  word, language, learning, learn, help, importa...   \n",
       "3  language, learning, learn, phrase, important, ...   \n",
       "4  word, learning, language, learn, help, reading...   \n",
       "5  language, word, learning, learn, help, time, n...   \n",
       "6  learn, language, learning, word, thing, phrase...   \n",
       "7  word, language, thing, learn, learning, phrase...   \n",
       "8  language, word, learning, phrase, learn, readi...   \n",
       "9  word, language, learning, learn, help, reading...   \n",
       "\n",
       "                                                Text  \n",
       "0  If you want to learn a new language ''quickly'...  \n",
       "1  This is especially important when you are havi...  \n",
       "2  Try learning to count to ten since 1-10 is usu...  \n",
       "3  Thatâ€™s all a normal part of the language-lea...  \n",
       "4  When you're learning a new language youâ€™ll g...  \n",
       "5  In turn, better reading and pronunciation can ...  \n",
       "6  If you can visit and spend some time in a coun...  \n",
       "7  Learning a language within the context of cult...  \n",
       "8  But when they say five years, they probably me...  \n",
       "9  You might find yourself in situations where yo...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(len(tksen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9fd90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet.to_csv(r\"C:\\Users\\kanis\\Major-Project\\PreClusteringData\\mrdfet.csv\")\n",
    "#saving the most representative document for each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91c2b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.to_csv(r\"C:\\Users\\kanis\\Major-Project\\PreClusteringData\\dt.csv\")\n",
    "#saving the topic wise information for each sentence or document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11e32411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "\n",
    "#making the list of clusters with their sentences classfied accordingly \n",
    "listofclusters = [None] * num_topics\n",
    "for i in range(num_topics):\n",
    "    listofclusters[i] = []\n",
    "\n",
    "with open(r'C:\\Users\\kanis\\Major-Project\\PreClusteringData\\dt.csv', 'r',encoding=\"utf8\") as csvfile :\n",
    "    datareader = csv.reader(csvfile)\n",
    "    for row in datareader:\n",
    "        if row[0] == '':\n",
    "            continue\n",
    "        listofclusters[int(row[2])].append(row[5]) # saving the sentence(row5) in its dominant topic(row2) cluster\n",
    "     \n",
    "    \n",
    "#loop for reprsentation\n",
    "i = 0\n",
    "for item in listofclusters :\n",
    "    #print(\"topic cluster no. \"+str(i))\n",
    "    #for sentence in item:\n",
    "        #print(sentence)\n",
    "    #print()\n",
    "    i = i + 1\n",
    "    \n",
    "#print(listofclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f8b2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d78b43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db4775f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofsentence_vectors = []\n",
    "sentence_vectors = []\n",
    "for sentences in listofclusters:\n",
    "    for i in sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((100,))\n",
    "        sentence_vectors.append(v)\n",
    "    listofsentence_vectors.append(sentence_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c190a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c385e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "k = 0\n",
    "\n",
    "listofsimmatrix = []\n",
    "for sentences in listofclusters:\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    #We will use Cosine Similarity to compute the similarity between a pair of sentences.\n",
    "\n",
    "\n",
    "#And initialize the matrix with cosine similarity scores.\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(listofsentence_vectors[k][i].reshape(1,100), listofsentence_vectors[k][j].reshape(1,100))[0,0]\n",
    "    k=k+1\n",
    "    listofsimmatrix.append(sim_mat)\n",
    "#print(len(listofsimmatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe7674d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofsubsum = [None] * num_topics\n",
    "for i in range(num_topics):\n",
    "    listofsubsum[i] = []\n",
    "\n",
    "k = 0\n",
    "for sim_mat in listofsimmatrix:\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(listofclusters[k])), reverse=True)\n",
    "    for i in range(int(len(ranked_sentences)/3)):\n",
    "        listofsubsum[k].append(ranked_sentences[i][1])\n",
    "    k=k+1\n",
    "#print(listofsubsum)\n",
    "#print()\n",
    "#print(listofclusters)\n",
    "\n",
    "\n",
    "#generating the final list\n",
    "finallist = []\n",
    "for lis in listofsubsum :\n",
    "    for sent in lis :\n",
    "        if len(sent)>0:\n",
    "            finallist.append(sent)\n",
    "#print(finallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b355dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating dictionary to arrange summaryin chronological order\n",
    "dictofsent = {}\n",
    "k = 0\n",
    "for sent in tksen :\n",
    "    dictofsent[sent] = k\n",
    "    k=k+1\n",
    "summarytosave=sorted(finallist, key=dictofsent.get)\n",
    "#print(summarytosave)\n",
    "\n",
    "sample = \"\"\n",
    "for sent in summarytosave:\n",
    "    sample += sent \n",
    "    sample += ' '\n",
    "\n",
    "listsave = []\n",
    "listsave.append(sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9103284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lexrank \n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "446da9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersummary = [None] * num_topics\n",
    "for i in range(num_topics):\n",
    "    clustersummary[i] = []\n",
    "   \n",
    "k =0\n",
    "for cluster in listofclusters:\n",
    "    sentences = \"\"\n",
    "    for sent in cluster :\n",
    "        sentences += sent\n",
    "        sentences += ' '\n",
    "    p = PlaintextParser.from_string(sentences, Tokenizer(\"english\"))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summ = summarizer(p.document, int(len(cluster)/3))\n",
    "    for s in summ:\n",
    "        clustersummary[k].append(s)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78ba4163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possibly the easiest thing you can do is watch television shows or movies in the language you are trying to learn. Try to avoid subtitles, so you donâ€™t develop a reliance on them. To make things easier, try to watch shows or movies whose plots you are already familiar withâ€”like kids' cartoons or dubbed versions of English movieâ€”knowing the context will help you to decipher the meanings of words and phrases. Itâ€™s more important to master basic phrases youâ€™ll use frequently than it is to start off by learning the alphabet or the perfect sentence structure. In addition, looking up the word and using it immediately in a sentence will help you to commit the word to memory. Most language learning apps offer both a free version and a pro/premium version with more access to additional lessons and features. If you want to learn a new language ''quickly'' (that is, in the space of a few weeks or months), you're going to have to commit to studying the language for a couple of hours ''per day''. \n",
      "\n",
      "As your language level progresses, you can move on to more advanced reading material like newspapers and magazines. Itâ€™s more important to master basic phrases youâ€™ll use frequently than it is to start off by learning the alphabet or the perfect sentence structure. Possibly the easiest thing you can do is watch television shows or movies in the language you are trying to learn. When you read out loud, rather than silently, you can work on both your overall reading comprehension and pronunciation skills. Mastering everyday conversation will let you hit the ground running. Try to avoid subtitles, so you donâ€™t develop a reliance on them. To make things easier, try to watch shows or movies whose plots you are already familiar withâ€”like kids' cartoons or dubbed versions of English movieâ€”knowing the context will help you to decipher the meanings of words and phrases. \n"
     ]
    }
   ],
   "source": [
    "finallexsumm = \"\"\n",
    "for subsum in clustersummary:\n",
    "    if len(subsum)==0:\n",
    "        continue\n",
    "    for sent in subsum:\n",
    "        if len(str(sent))>0:\n",
    "            finallexsumm += str(sent)\n",
    "            finallexsumm += ' '\n",
    "#print(finallexsumm)\n",
    "\n",
    "\n",
    "listsave.append(finallexsumm)\n",
    "listsave.append(summarylex)\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Generated Summary\\gen_sum01.pkl\",\"wb\") as fp:\n",
    "    pickle.dump(listsave,fp)\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Generated Summary\\gen_sum01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "    print(data[0])\n",
    "    print()\n",
    "    print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4665fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283eae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
