{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the variables from file : dictionary and tdf/corpus\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "dictionary = data[0]\n",
    "termdocfreq = data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6384808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.037*\"language\" + 0.022*\"word\" + 0.022*\"learning\" + 0.018*\"learn\" + '\n",
      "  '0.018*\"thing\" + 0.015*\"reading\" + 0.014*\"phrase\" + 0.013*\"grammar\" + '\n",
      "  '0.012*\"help\" + 0.010*\"important\"'),\n",
      " (1,\n",
      "  '0.032*\"language\" + 0.025*\"thing\" + 0.021*\"show\" + 0.020*\"learn\" + '\n",
      "  '0.020*\"watch\" + 0.019*\"movie\" + 0.017*\"trying\" + 0.017*\"phrase\" + '\n",
      "  '0.016*\"word\" + 0.014*\"Try\"'),\n",
      " (2,\n",
      "  '0.026*\"word\" + 0.026*\"language\" + 0.022*\"learning\" + 0.017*\"learn\" + '\n",
      "  '0.014*\"phrase\" + 0.013*\"reading\" + 0.013*\"new\" + 0.013*\"help\" + '\n",
      "  '0.013*\"thing\" + 0.012*\"memorize\"'),\n",
      " (3,\n",
      "  '0.034*\"language\" + 0.033*\"word\" + 0.020*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.017*\"phrase\" + 0.016*\"reading\" + 0.015*\"thing\" + 0.014*\"important\" + '\n",
      "  '0.014*\"help\" + 0.012*\"time\"'),\n",
      " (4,\n",
      "  '0.035*\"language\" + 0.028*\"word\" + 0.027*\"learn\" + 0.024*\"learning\" + '\n",
      "  '0.016*\"reading\" + 0.014*\"phrase\" + 0.014*\"help\" + 0.014*\"time\" + '\n",
      "  '0.013*\"thing\" + 0.013*\"important\"'),\n",
      " (5,\n",
      "  '0.034*\"language\" + 0.027*\"word\" + 0.018*\"reading\" + 0.018*\"learning\" + '\n",
      "  '0.017*\"help\" + 0.015*\"phrase\" + 0.015*\"thing\" + 0.015*\"learn\" + '\n",
      "  '0.012*\"show\" + 0.011*\"pronunciation\"'),\n",
      " (6,\n",
      "  '0.030*\"language\" + 0.025*\"word\" + 0.025*\"learning\" + 0.021*\"learn\" + '\n",
      "  '0.020*\"phrase\" + 0.018*\"thing\" + 0.017*\"important\" + 0.015*\"reading\" + '\n",
      "  '0.014*\"help\" + 0.012*\"movie\"'),\n",
      " (7,\n",
      "  '0.032*\"word\" + 0.030*\"language\" + 0.020*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.013*\"reading\" + 0.013*\"help\" + 0.013*\"phrase\" + 0.012*\"thing\" + '\n",
      "  '0.012*\"important\" + 0.012*\"time\"'),\n",
      " (8,\n",
      "  '0.029*\"word\" + 0.026*\"language\" + 0.022*\"learning\" + 0.022*\"learn\" + '\n",
      "  '0.018*\"thing\" + 0.015*\"help\" + 0.015*\"reading\" + 0.015*\"phrase\" + '\n",
      "  '0.011*\"time\" + 0.011*\"new\"'),\n",
      " (9,\n",
      "  '0.036*\"language\" + 0.029*\"word\" + 0.022*\"learn\" + 0.022*\"learning\" + '\n",
      "  '0.016*\"thing\" + 0.015*\"phrase\" + 0.015*\"help\" + 0.014*\"reading\" + '\n",
      "  '0.013*\"important\" + 0.011*\"trying\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=termdocfreq,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=num_topics)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[termdocfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09afa658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis==3.2.1\n",
      "  Using cached pyLDAvis-3.2.1.tar.gz (1.7 MB)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.24.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (1.2.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (2.11.3)\n",
      "Requirement already satisfied: numexpr in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (2.7.3)\n",
      "Requirement already satisfied: future in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (0.18.2)\n",
      "Requirement already satisfied: funcy in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (2.0)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pyLDAvis==3.2.1) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis==3.2.1) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis==3.2.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kanis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.17.0->pyLDAvis==3.2.1) (1.15.0)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (setup.py): started\n",
      "  Building wheel for pyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.1-py2.py3-none-any.whl size=136161 sha256=cda57a712f34ebceca596da5896dcffa760b1d029be313914b243af45ab6435c\n",
      "  Stored in directory: c:\\users\\kanis\\appdata\\local\\pip\\cache\\wheels\\ae\\5f\\79\\278ffb79ffde795f9686b558a8e313971ee0d3a914105d57dd\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: pyLDAvis\n",
      "  Attempting uninstall: pyLDAvis\n",
      "    Found existing installation: pyLDAvis 3.4.0\n",
      "    Uninstalling pyLDAvis-3.4.0:\n",
      "      Successfully uninstalled pyLDAvis-3.4.0\n",
      "Successfully installed pyLDAvis-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "896b576c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m LDAvis_prepared \u001b[38;5;241m=\u001b[39m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtermdocfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43msort_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py:123\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:432\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    430\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 432\u001b[0m topic_info \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m token_table \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency, start_index)\n\u001b[0;32m    436\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion, start_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:243\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[0;32m    237\u001b[0m default_term_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaliency\u001b[39m\u001b[38;5;124m'\u001b[39m: saliency,\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m'\u001b[39m: vocab,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m: term_frequency,\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m'\u001b[39m: term_frequency,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDefault\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m--> 243\u001b[0m default_term_info \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_term_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    246\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pyLDAvis\n",
    "import os \n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary,sort_topics=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08924e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanis\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b7c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
