{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df4215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the variables from file : dictionary and tdf/corpus\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "dictionary = data[0]\n",
    "termdocfreq = data[1]\n",
    "finallemma = data[2]\n",
    "feedtodict = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6384808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.037*\"word\" + 0.031*\"language\" + 0.024*\"learning\" + 0.021*\"learn\" + '\n",
      "  '0.015*\"help\" + 0.014*\"thing\" + 0.013*\"one\" + 0.012*\"reading\" + 0.011*\"day\" '\n",
      "  '+ 0.011*\"important\"'),\n",
      " (1,\n",
      "  '0.035*\"language\" + 0.033*\"thing\" + 0.029*\"watch\" + 0.029*\"show\" + '\n",
      "  '0.029*\"movie\" + 0.025*\"reading\" + 0.025*\"phrase\" + 0.023*\"trying\" + '\n",
      "  '0.022*\"like\" + 0.016*\"Possibly\"'),\n",
      " (2,\n",
      "  '0.038*\"word\" + 0.027*\"language\" + 0.023*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.017*\"help\" + 0.013*\"important\" + 0.012*\"thing\" + 0.012*\"phrase\" + '\n",
      "  '0.011*\"reading\" + 0.011*\"version\"'),\n",
      " (3,\n",
      "  '0.033*\"language\" + 0.027*\"learning\" + 0.026*\"learn\" + 0.024*\"phrase\" + '\n",
      "  '0.020*\"important\" + 0.020*\"word\" + 0.018*\"thing\" + 0.018*\"reading\" + '\n",
      "  '0.015*\"understand\" + 0.014*\"sentence\"'),\n",
      " (4,\n",
      "  '0.017*\"word\" + 0.017*\"learning\" + 0.016*\"language\" + 0.013*\"learn\" + '\n",
      "  '0.010*\"help\" + 0.009*\"reading\" + 0.008*\"new\" + 0.008*\"phrase\" + '\n",
      "  '0.008*\"time\" + 0.008*\"grammar\"'),\n",
      " (5,\n",
      "  '0.040*\"language\" + 0.031*\"word\" + 0.025*\"learning\" + 0.019*\"learn\" + '\n",
      "  '0.013*\"help\" + 0.012*\"time\" + 0.012*\"new\" + 0.011*\"reading\" + 0.011*\"day\" + '\n",
      "  '0.011*\"phrase\"'),\n",
      " (6,\n",
      "  '0.029*\"learn\" + 0.028*\"language\" + 0.023*\"learning\" + 0.021*\"word\" + '\n",
      "  '0.019*\"thing\" + 0.018*\"phrase\" + 0.018*\"reading\" + 0.014*\"day\" + '\n",
      "  '0.014*\"important\" + 0.013*\"memorize\"'),\n",
      " (7,\n",
      "  '0.031*\"word\" + 0.031*\"language\" + 0.020*\"thing\" + 0.017*\"learn\" + '\n",
      "  '0.016*\"learning\" + 0.015*\"phrase\" + 0.014*\"help\" + 0.014*\"watch\" + '\n",
      "  '0.012*\"reading\" + 0.012*\"trying\"'),\n",
      " (8,\n",
      "  '0.032*\"language\" + 0.032*\"word\" + 0.023*\"learning\" + 0.018*\"phrase\" + '\n",
      "  '0.018*\"learn\" + 0.013*\"reading\" + 0.013*\"help\" + 0.012*\"time\" + '\n",
      "  '0.011*\"sentence\" + 0.010*\"important\"'),\n",
      " (9,\n",
      "  '0.035*\"word\" + 0.025*\"language\" + 0.022*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.018*\"help\" + 0.016*\"reading\" + 0.016*\"phrase\" + 0.015*\"thing\" + '\n",
      "  '0.014*\"important\" + 0.012*\"pronunciation\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=termdocfreq,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=num_topics,random_state=100, chunksize=100, passes=10, per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[termdocfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09afa658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896b576c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m LDAvis_prepared \u001b[38;5;241m=\u001b[39m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtermdocfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43msort_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\gensim.py:124\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvis_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:440\u001b[0m, in \u001b[0;36mprepare\u001b[1;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[0;32m    438\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 440\u001b[0m topic_info \u001b[38;5;241m=\u001b[39m \u001b[43m_topic_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic_term_dists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_proportion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mterm_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm_topic_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m token_table \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency, start_index)\n\u001b[0;32m    444\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion, start_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:247\u001b[0m, in \u001b[0;36m_topic_info\u001b[1;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Order the terms for the \"default\" view by decreasing saliency:\u001b[39;00m\n\u001b[0;32m    241\u001b[0m default_term_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaliency\u001b[39m\u001b[38;5;124m'\u001b[39m: saliency,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m'\u001b[39m: vocab,\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m: term_frequency,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m'\u001b[39m: term_frequency,\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDefault\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m--> 247\u001b[0m default_term_info \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_term_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaliency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Rounding Freq and Total to integer values to match LDAvis code:\u001b[39;00m\n\u001b[0;32m    250\u001b[0m default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(default_term_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pyLDAvis\n",
    "import os \n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary,sort_topics=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d08924e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41130767176413513\n",
      "\n",
      "Perplexity:  -5.128441183809427\n"
     ]
    }
   ],
   "source": [
    "#coherence and score \n",
    "from gensim.models import CoherenceModel\n",
    "# instantiate topic coherence model\n",
    "import numpy as np\n",
    "newcorpus = []\n",
    "for lis in finallemma :\n",
    "    for w in lis :\n",
    "        if len(w)>2:\n",
    "            newcorpus.append(w)\n",
    "\n",
    "cm = CoherenceModel(model=lda_model, texts=feedtodict, dictionary=dictionary, coherence='c_v')\n",
    "with np.errstate(invalid='ignore'):\n",
    "    coherence_lda = cm.get_coherence()\n",
    "    print('Coherence: ', coherence_lda)                \n",
    "# getting topic coherence score \n",
    "\n",
    "\n",
    "#getting the perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(termdocfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b7c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
