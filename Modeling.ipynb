{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the variables from file : dictionary and tdf/corpus\n",
    "with open(r\"C:\\Users\\kanis\\Major-Project\\Tokens\\tkn01.pkl\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "dictionary = data[0]\n",
    "termdocfreq = data[1]\n",
    "finallemma = data[2]\n",
    "feedtodict = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6384808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.037*\"word\" + 0.031*\"language\" + 0.023*\"learning\" + 0.021*\"learn\" + '\n",
      "  '0.015*\"help\" + 0.014*\"thing\" + 0.013*\"one\" + 0.012*\"reading\" + '\n",
      "  '0.011*\"important\" + 0.011*\"day\"'),\n",
      " (1,\n",
      "  '0.035*\"language\" + 0.034*\"thing\" + 0.030*\"watch\" + 0.030*\"show\" + '\n",
      "  '0.029*\"movie\" + 0.026*\"reading\" + 0.024*\"phrase\" + 0.024*\"trying\" + '\n",
      "  '0.023*\"like\" + 0.017*\"Possibly\"'),\n",
      " (2,\n",
      "  '0.038*\"word\" + 0.027*\"language\" + 0.023*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.017*\"help\" + 0.013*\"important\" + 0.012*\"thing\" + 0.012*\"phrase\" + '\n",
      "  '0.011*\"reading\" + 0.011*\"time\"'),\n",
      " (3,\n",
      "  '0.033*\"language\" + 0.027*\"learning\" + 0.025*\"learn\" + 0.024*\"phrase\" + '\n",
      "  '0.020*\"important\" + 0.019*\"word\" + 0.018*\"thing\" + 0.018*\"reading\" + '\n",
      "  '0.015*\"understand\" + 0.015*\"sentence\"'),\n",
      " (4,\n",
      "  '0.018*\"word\" + 0.017*\"learning\" + 0.016*\"language\" + 0.013*\"learn\" + '\n",
      "  '0.010*\"help\" + 0.009*\"reading\" + 0.008*\"new\" + 0.008*\"phrase\" + '\n",
      "  '0.008*\"grammar\" + 0.008*\"time\"'),\n",
      " (5,\n",
      "  '0.041*\"language\" + 0.031*\"word\" + 0.025*\"learning\" + 0.019*\"learn\" + '\n",
      "  '0.013*\"help\" + 0.012*\"time\" + 0.012*\"new\" + 0.011*\"reading\" + 0.011*\"day\" + '\n",
      "  '0.011*\"phrase\"'),\n",
      " (6,\n",
      "  '0.029*\"learn\" + 0.028*\"language\" + 0.023*\"learning\" + 0.022*\"word\" + '\n",
      "  '0.018*\"thing\" + 0.018*\"phrase\" + 0.017*\"reading\" + 0.014*\"day\" + '\n",
      "  '0.014*\"important\" + 0.013*\"memorize\"'),\n",
      " (7,\n",
      "  '0.032*\"word\" + 0.031*\"language\" + 0.020*\"thing\" + 0.017*\"learn\" + '\n",
      "  '0.016*\"learning\" + 0.015*\"phrase\" + 0.014*\"help\" + 0.013*\"watch\" + '\n",
      "  '0.012*\"reading\" + 0.012*\"trying\"'),\n",
      " (8,\n",
      "  '0.032*\"language\" + 0.032*\"word\" + 0.023*\"learning\" + 0.018*\"phrase\" + '\n",
      "  '0.018*\"learn\" + 0.013*\"reading\" + 0.013*\"help\" + 0.012*\"time\" + '\n",
      "  '0.011*\"sentence\" + 0.010*\"important\"'),\n",
      " (9,\n",
      "  '0.035*\"word\" + 0.025*\"language\" + 0.022*\"learning\" + 0.020*\"learn\" + '\n",
      "  '0.018*\"help\" + 0.016*\"reading\" + 0.016*\"phrase\" + 0.015*\"thing\" + '\n",
      "  '0.014*\"important\" + 0.012*\"pronunciation\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=termdocfreq,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=num_topics,random_state=100, chunksize=100, passes=10, per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[termdocfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09afa658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08924e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.4157517396267627\n",
      "\n",
      "Perplexity:  -5.1279096613698245\n"
     ]
    }
   ],
   "source": [
    "#coherence and score \n",
    "from gensim.models import CoherenceModel\n",
    "# instantiate topic coherence model\n",
    "import numpy as np\n",
    "newcorpus = []\n",
    "for lis in finallemma :\n",
    "    for w in lis :\n",
    "        if len(w)>2:\n",
    "            newcorpus.append(w)\n",
    "\n",
    "cm = CoherenceModel(model=lda_model, texts=feedtodict, dictionary=dictionary, coherence='c_v')\n",
    "with np.errstate(invalid='ignore'):\n",
    "    coherence_lda = cm.get_coherence()\n",
    "    print('Coherence: ', coherence_lda)                \n",
    "# getting topic coherence score \n",
    "\n",
    "\n",
    "#getting the perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(termdocfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896b576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle \n",
    "#import pyLDAvis\n",
    "#import os \n",
    "#import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "#num_topics = 10\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "#vis = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary,sort_topics = 'false')\n",
    "#vis\n",
    "#LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "#LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, termdocfreq, dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d69e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a6b7c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774973</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819981</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990998</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991260</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991344</td>\n",
       "      <td>language, thing, watch, show, movie, reading, ...</td>\n",
       "      <td>[Possibly, easiest, thing, watch, television, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib   \n",
       "0             0               1            0.549954  \\\n",
       "1             1               1            0.699966   \n",
       "2             2               1            0.774973   \n",
       "3             3               1            0.819981   \n",
       "4             4               1            0.849985   \n",
       "..          ...             ...                 ...   \n",
       "95           95               1            0.990998   \n",
       "96           96               1            0.991087   \n",
       "97           97               1            0.991175   \n",
       "98           98               1            0.991260   \n",
       "99           99               1            0.991344   \n",
       "\n",
       "                                             Keywords   \n",
       "0   language, thing, watch, show, movie, reading, ...  \\\n",
       "1   language, thing, watch, show, movie, reading, ...   \n",
       "2   language, thing, watch, show, movie, reading, ...   \n",
       "3   language, thing, watch, show, movie, reading, ...   \n",
       "4   language, thing, watch, show, movie, reading, ...   \n",
       "..                                                ...   \n",
       "95  language, thing, watch, show, movie, reading, ...   \n",
       "96  language, thing, watch, show, movie, reading, ...   \n",
       "97  language, thing, watch, show, movie, reading, ...   \n",
       "98  language, thing, watch, show, movie, reading, ...   \n",
       "99  language, thing, watch, show, movie, reading, ...   \n",
       "\n",
       "                                                 Text  \n",
       "0                                          [Possibly]  \n",
       "1                                 [Possibly, easiest]  \n",
       "2                          [Possibly, easiest, thing]  \n",
       "3                   [Possibly, easiest, thing, watch]  \n",
       "4       [Possibly, easiest, thing, watch, television]  \n",
       "..                                                ...  \n",
       "95  [Possibly, easiest, thing, watch, television, ...  \n",
       "96  [Possibly, easiest, thing, watch, television, ...  \n",
       "97  [Possibly, easiest, thing, watch, television, ...  \n",
       "98  [Possibly, easiest, thing, watch, television, ...  \n",
       "99  [Possibly, easiest, thing, watch, television, ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the dominant topics \n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts=feedtodict):\n",
    "    # Init output\n",
    "    \n",
    "    dp = []\n",
    "    pc = []\n",
    "    tk = []\n",
    "    \n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        #print(row_list)\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                #print(topic_keywords + \" \"+str(topic_num)+\" \"+str(prop_topic))\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, pd.Series([int(topic_num), round(prop_topic,4), topic_keywords])], ignore_index=True)\n",
    "                #df = pd.DataFrame({'Dominant_Topic': topic_num,'Perc_Contribution':prop_topic,'Topic_Keywords':topic_keywords})\n",
    "                #sent_topics_df = pd.concat([sent_topics_df, df], ignore_index=True)\n",
    "                dp.append(topic_num)\n",
    "                pc.append(prop_topic)\n",
    "                tk.append(topic_keywords)\n",
    "            else:\n",
    "                break\n",
    "   \n",
    "    sent_topics_df = pd.DataFrame({'Dominant_Topic' : dp, 'perc_contribution':pc, 'topic_keywords':tk })\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "    \n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=termdocfreq, texts=feedtodict)\n",
    "df_topic_sents_keywords.head(10)\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53631d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74634c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
